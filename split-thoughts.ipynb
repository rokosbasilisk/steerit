{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6575890-608a-47bf-b858-690b22dba889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af31a7c6-f82b-4a89-b4bc-74a41cce3f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa78ddeb42f4b18950625ac7fb4bf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Labeling chains:   0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167] ERROR: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60)\n",
      "✅ Saved labeled chains to gsm8k_chains_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script: label_gsm8k_thoughts_parallel.py\n",
    "\n",
    "Like before, but uses a ThreadPoolExecutor to label multiple chains in parallel.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ─── Configuration ───────────────────────────────────────────────────────────\n",
    "INPUT_DF_PATH   = \"reasoning_traces.csv\"\n",
    "OUTPUT_CSV      = \"gsm8k_chains_labeled.csv\"\n",
    "MODEL           = \"gpt-4\"\n",
    "SYSTEM_PROMPT   = (\n",
    "    \"You will be given a math question and the chain of thought (broken into numbered steps).  \"\n",
    "    \"Your job is to tell me which steps are truly necessary to arrive at the final answer \"\n",
    "    \"(i.e. non‐redundant reasoning), and which are fluff or repetition.  \"\n",
    "    \"Return your answer as a JSON object with two arrays: \"\n",
    "    \"`required` (list of step indices) and `redundant` (list of step indices).\"\n",
    ")\n",
    "MAX_WORKERS     = 8   # number of concurrent threads\n",
    "TIMEOUT_SECONDS = 60  # per-request timeout\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def classify_thoughts(question: str, thoughts: list[str]) -> tuple[list[int], list[int]]:\n",
    "    numbered = \"\\n\".join(f\"{i+1}. {t}\" for i,t in enumerate(thoughts))\n",
    "    user = (\n",
    "        f\"Question:\\n{question}\\n\\n\"\n",
    "        f\"Chain of thought (each step numbered below):\\n{numbered}\\n\\n\"\n",
    "        \"Which step numbers are REQUIRED vs REDUNDANT?\"\n",
    "    )\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\",   \"content\": user}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        request_timeout=TIMEOUT_SECONDS\n",
    "    )\n",
    "    content = resp.choices[0].message.content.strip()\n",
    "    try:\n",
    "        j = json.loads(content)\n",
    "        return j.get(\"required\", []), j.get(\"redundant\", [])\n",
    "    except json.JSONDecodeError:\n",
    "        return [], []\n",
    "\n",
    "def worker(row):\n",
    "    q     = row[\"question\"]\n",
    "    chain = row[\"chain_of_thought\"]\n",
    "    thoughts = [t.strip() for t in chain.split(\"\\n\\n\") if t.strip()]\n",
    "    req, red = classify_thoughts(q, thoughts)\n",
    "    return req, red\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(INPUT_DF_PATH)\n",
    "    required_idxs  = [None] * len(df)\n",
    "    redundant_idxs = [None] * len(df)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:\n",
    "        # submit all jobs\n",
    "        futures = {exe.submit(worker, df.iloc[i]): i for i in range(len(df))}\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Labeling chains\"):\n",
    "            idx = futures[fut]\n",
    "            try:\n",
    "                req, red = fut.result()\n",
    "            except Exception as e:\n",
    "                req, red = [], []\n",
    "                print(f\"[{idx}] ERROR: {e}\")\n",
    "            required_idxs[idx]  = req\n",
    "            redundant_idxs[idx] = red\n",
    "\n",
    "    df[\"required_indices\"]  = required_idxs\n",
    "    df[\"redundant_indices\"] = redundant_idxs\n",
    "\n",
    "    def pick(inds, thoughts):\n",
    "        return \"\\n\\n\".join(thoughts[i-1] for i in inds if 1 <= i <= len(thoughts))\n",
    "\n",
    "    # extract the text for required/redundant\n",
    "    df[\"required_thoughts\"]  = df.apply(\n",
    "        lambda r: pick(r.required_indices, r.chain_of_thought.split(\"\\n\\n\")), axis=1\n",
    "    )\n",
    "    df[\"redundant_thoughts\"] = df.apply(\n",
    "        lambda r: pick(r.redundant_indices, r.chain_of_thought.split(\"\\n\\n\")), axis=1\n",
    "    )\n",
    "\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"✅ Saved labeled chains to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d245c20-0dfa-4819-83e4-b2b363e2d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gsm8k_chains_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859fabf0-e76c-4386-bc15-2bd8513357a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          1200 non-null   int64 \n",
      " 1   idx                 1200 non-null   int64 \n",
      " 2   question            1200 non-null   object\n",
      " 3   reference_answer    1200 non-null   object\n",
      " 4   chain_of_thought    1200 non-null   object\n",
      " 5   token_lengths       1200 non-null   int64 \n",
      " 6   num_thoughts        1200 non-null   int64 \n",
      " 7   required_indices    1200 non-null   object\n",
      " 8   redundant_indices   1200 non-null   object\n",
      " 9   required_thoughts   1199 non-null   object\n",
      " 10  redundant_thoughts  1198 non-null   object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71dd485-2fa5-4f8b-8ab0-7818f30af660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmented DataFrame saved to gsm8k_chains_labeled_with_tokens.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ─── Config ────────────────────────────────────────────────────────────────\n",
    "MODEL_NAME    = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "OUTPUT_CSV    = \"gsm8k_chains_labeled_with_tokens.csv\"\n",
    "\n",
    "# ─── Load the labeled chains DataFrame ────────────────────────────────────\n",
    "df = pd.read_csv('gsm8k_chains_labeled.csv')\n",
    "\n",
    "# ─── Initialize tokenizer ─────────────────────────────────────────────────\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# ─── Make sure empty entries are strings ───────────────────────────────────\n",
    "for c in [\"chain_of_thought\", \"required_thoughts\", \"redundant_thoughts\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = \"\"\n",
    "    else:\n",
    "        df[c] = df[c].fillna(\"\")\n",
    "\n",
    "# ─── Helper to count tokens (no special tokens) ────────────────────────────\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text, add_special_tokens=False))\n",
    "\n",
    "# ─── Compute and append the new columns ────────────────────────────────────\n",
    "df[\"total_tokens\"]     = df[\"chain_of_thought\"].map(count_tokens)\n",
    "df[\"required_tokens\"]  = df[\"required_thoughts\"].map(count_tokens)\n",
    "df[\"redundant_tokens\"] = df[\"redundant_thoughts\"].map(count_tokens)\n",
    "\n",
    "# ─── Percent of tokens that are redundant (could be saved) ───────────────\n",
    "# guard zero‐division\n",
    "df[\"token_saving_pct\"] = (\n",
    "    df[\"redundant_tokens\"] / df[\"total_tokens\"].replace(0, 1)\n",
    ") * 100\n",
    "\n",
    "# ─── Save the augmented DataFrame ─────────────────────────────────────────\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"✅ Augmented DataFrame saved to {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5b3590c-47b9-4851-aeac-aaf98d109ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.367159478610795"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_saving_pct'].median() # 63% tokens can be saved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
