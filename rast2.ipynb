{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3ea1e0-b399-4681-a7b5-a24d2bcb2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install repeng accelerate datasets matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e299f5-03c0-4904-9e06-bfa26ffffd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ loaded ctrl‐vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (19690 > 16384). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk=16  val_acc= 93.6%\n",
      "chunk=64  val_acc= 95.6%\n",
      "▶ Using chunk_size=64, platt a=0.003, b=4.373\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# RASPID – “fluff PID” v2 + full AIME eval\n",
    "# -------------------------------------------------\n",
    "# 1) build contrastive control vector\n",
    "# 2) train + calibrate fluff‐prob classifier\n",
    "# 3) define baseline & RASPID generators\n",
    "# 4) run run_aime_benchmark() and report\n",
    "\n",
    "import os, random, math, re, warnings\n",
    "import numpy as np, pandas as pd, torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from repeng import ControlModel, ControlVector, DatasetEntry\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ─── CONFIG & REPRO ────────────────────────────────────────────────────────\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "MODEL_NAME   = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE        = torch.float32\n",
    "EMB_LAYER    = 20\n",
    "CTRL_VEC_PT  = \"ctrl_vector_clean_minus_fluff.pt\"\n",
    "MAX_CV_EX    = 800\n",
    "MAX_CLF_EX   = 200\n",
    "CHUNK_SIZES  = [16,64]\n",
    "MAX_CHUNKS   = 5000\n",
    "BATCH_SIZE   = 16\n",
    "MAX_TOKENS   = 4096\n",
    "\n",
    "# ─── LOAD MODELS ───────────────────────────────────────────────────────────\n",
    "tokenizer    = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "base_model   = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=DTYPE,\n",
    "    device_map=\"auto\" if DEVICE==\"cuda\" else None\n",
    ").eval()\n",
    "control_model = ControlModel(base_model,[EMB_LAYER])  # relies on base‘s device_map\n",
    "\n",
    "# ─── 1) CONTRASTIVE CONTROL VECTOR ─────────────────────────────────────────\n",
    "def build_contrastive_vector(n_ex=MAX_CV_EX, layer=EMB_LAYER):\n",
    "    ds = load_dataset(\"rb/aime_reasoning\",\"default\")[\"train\"].select(range(n_ex))\n",
    "    clean_txt = [r[\"refined_reasoning\"] for r in ds]\n",
    "    fluff_txt = [r[\"reasoning_content\"]   for r in ds]\n",
    "    def embed(batch):\n",
    "        toks = tokenizer(batch, padding=True, truncation=True,\n",
    "                         max_length=256, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.inference_mode():\n",
    "            h = base_model(**toks, output_hidden_states=True\n",
    "                          ).hidden_states[layer][:,0]\n",
    "        return h.cpu()\n",
    "    v = embed(clean_txt).mean(0) - embed(fluff_txt).mean(0)\n",
    "    v = v / (v.norm()+1e-12)\n",
    "    return ControlVector(\"qwen2\", {layer: v.numpy()})\n",
    "\n",
    "if os.path.exists(CTRL_VEC_PT):\n",
    "    ctrl_vec = torch.load(CTRL_VEC_PT, map_location=\"cpu\", weights_only=False)\n",
    "    print(\"✅ loaded ctrl‐vec\")\n",
    "else:\n",
    "    print(\"⚙️  training ctrl‐vec …\")\n",
    "    ctrl_vec = build_contrastive_vector()\n",
    "    torch.save(ctrl_vec, CTRL_VEC_PT)\n",
    "    print(\"💾 saved to\", CTRL_VEC_PT)\n",
    "\n",
    "# ─── 2) BUILD & TRAIN CHUNK FLUFF‐PROB CLASSIFIER ─────────────────────────\n",
    "def build_chunk_dataset(cs):\n",
    "    ds = load_dataset(\"rb/aime_reasoning\",\"default\")[\"train\"].select(range(MAX_CLF_EX))\n",
    "    chunks, labels = [], []\n",
    "    for r in ds:\n",
    "        for txt,lbl in [(r[\"refined_reasoning\"],0),(r[\"reasoning_content\"],1)]:\n",
    "            ids = tokenizer.encode(txt)\n",
    "            for i in range(0, len(ids)-cs+1, cs):\n",
    "                chunks.append(tokenizer.decode(ids[i:i+cs], skip_special_tokens=True))\n",
    "                labels.append(lbl)\n",
    "    # cap total\n",
    "    if len(chunks) > MAX_CHUNKS:\n",
    "        idx = np.random.choice(len(chunks), MAX_CHUNKS, replace=False)\n",
    "        chunks = [chunks[i] for i in idx]\n",
    "        labels = [labels[i] for i in idx]\n",
    "    return chunks, np.array(labels)\n",
    "\n",
    "def embed_texts(texts, max_len):\n",
    "    feats=[]\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "        toks = tokenizer(texts[i:i+BATCH_SIZE], padding=True, truncation=True,\n",
    "                         max_length=max_len, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.inference_mode():\n",
    "            h = base_model(**toks, output_hidden_states=True\n",
    "                          ).hidden_states[EMB_LAYER].mean(1)\n",
    "        feats.append(h.cpu().numpy())\n",
    "    return np.vstack(feats)\n",
    "\n",
    "# grid‐search chunk size & platt scale\n",
    "CALIB = {}\n",
    "best_cs, best_acc, clf_best = None,0.0,None\n",
    "for cs in CHUNK_SIZES:\n",
    "    X_txt, y = build_chunk_dataset(cs)\n",
    "    X_emb   = embed_texts(X_txt, cs)\n",
    "    Xtr, Xval, ytr, yval = train_test_split(X_emb,y,test_size=0.2,\n",
    "                                             random_state=SEED,stratify=y)\n",
    "    clf = SGDClassifier(loss=\"log_loss\",max_iter=600,tol=1e-4,random_state=SEED)\n",
    "    clf.fit(Xtr,ytr)\n",
    "    acc = accuracy_score(yval, clf.predict(Xval))\n",
    "    print(f\"chunk={cs:2d}  val_acc={acc*100:5.1f}%\")\n",
    "    if acc > best_acc:\n",
    "        best_cs, best_acc, clf_best = cs, acc, clf\n",
    "        raw = clf.decision_function(Xval).reshape(-1,1)\n",
    "        platt = LogisticRegression(solver=\"lbfgs\").fit(raw, yval)\n",
    "        CALIB[\"a\"], CALIB[\"b\"] = platt.coef_[0,0], platt.intercept_[0]\n",
    "print(f\"▶ Using chunk_size={best_cs}, platt a={CALIB['a']:.3f}, b={CALIB['b']:.3f}\")\n",
    "\n",
    "# ─── 3) DEFINE GENERATORS ──────────────────────────────────────────────────\n",
    "@torch.inference_mode()\n",
    "def generate_baseline(prompt, max_tokens=MAX_TOKENS):\n",
    "    inp = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    out = base_model.generate(\n",
    "        **inp,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True, temperature=0.3,\n",
    "        top_p=0.9, repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    toks = out.shape[1] - inp.input_ids.shape[1]\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True), toks\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_raspid(prompt, max_tokens=MAX_TOKENS,\n",
    "                    chunk_size=best_cs, target_p=0.05,\n",
    "                    kp=0.25, ki=0.002, kd=0.0005, max_alpha=1.0,\n",
    "                    base_temp=1.0, steer_temp=0.3,\n",
    "                    init_free=40, steer_window=60, max_repeat=8,\n",
    "                    stop_regex=r\"\\\\boxed\\{[^{}]{1,12}\\}\", layer=EMB_LAYER):\n",
    "    stop_re = re.compile(stop_regex)\n",
    "    ids, past = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE).input_ids[0], None\n",
    "    out_ids = ids.clone()\n",
    "    α=I=D=prev_err=0.0\n",
    "    chunk_hidd= None; tok_in_chunk=0\n",
    "    steering_on=False; steer_start=0\n",
    "    rep_ctr=0; last_tok=None\n",
    "    a,b = CALIB[\"a\"], CALIB[\"b\"]\n",
    "\n",
    "    print(\"\\n*** RASPID LOG START ***\\nchunk | p_fluff |  err  |   α   | temp\")\n",
    "    while len(out_ids)-len(ids) < max_tokens:\n",
    "        L = len(out_ids)-len(ids)\n",
    "        if not steering_on and L>=init_free:\n",
    "            steering_on, steer_start = True, L\n",
    "        if steering_on and L-steer_start > steer_window:\n",
    "            steering_on, α, I, D = False,0,0,0\n",
    "\n",
    "        control_model.set_control(ctrl_vec, coeff=α if steering_on else 0.)\n",
    "        out = control_model(input_ids=out_ids[-1:].unsqueeze(0),\n",
    "                            past_key_values=past, use_cache=True,\n",
    "                            output_hidden_states=True)\n",
    "        past = out.past_key_values\n",
    "        logits = out.logits[0,-1]\n",
    "        h_last = out.hidden_states[layer][0,-1]\n",
    "\n",
    "        tok = out_ids[-1].item()\n",
    "        rep_ctr = rep_ctr+1 if tok==last_tok else 0\n",
    "        last_tok = tok\n",
    "        if rep_ctr>=max_repeat: break\n",
    "\n",
    "        chunk_hidd = h_last if chunk_hidd is None else chunk_hidd + h_last\n",
    "        tok_in_chunk += 1\n",
    "\n",
    "        if tok_in_chunk >= chunk_size:\n",
    "            feat   = (chunk_hidd/chunk_size).cpu().unsqueeze(0).numpy()\n",
    "            raw    = clf_best.decision_function(feat)[0]\n",
    "            p_fluff= 1/(1+math.exp(- (a*raw + b) ))\n",
    "            err    = p_fluff - target_p\n",
    "\n",
    "            I    += ki*err\n",
    "            D     = 0.9*D + 0.1*kd*(err-prev_err)\n",
    "            prev_err = err\n",
    "            α     = float(np.clip(kp*err + I + D, 0.0, max_alpha))\n",
    "            temp  = base_temp*(1-α/max_alpha) + steer_temp*(α/max_alpha)\n",
    "            print(f\"{chunk_size:5d} | {p_fluff:7.3f} | {err:+.3f} | \"\n",
    "                  f\"{α:5.3f} | {temp:5.3f}\")\n",
    "\n",
    "            chunk_hidd, tok_in_chunk = None, 0\n",
    "\n",
    "        temp  = base_temp*(1-α/max_alpha) + steer_temp*(α/max_alpha)\n",
    "        probs = torch.softmax(logits/temp, dim=-1)\n",
    "        nxt   = torch.multinomial(probs,1).item()\n",
    "        out_ids = torch.cat([out_ids, torch.tensor([nxt],device=DEVICE)])\n",
    "        if stop_re.search(tokenizer.decode([nxt])) or nxt==tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    print(\"*** RASPID LOG END ***\\n\")\n",
    "    return tokenizer.decode(out_ids, skip_special_tokens=True), len(out_ids)-len(ids)\n",
    "\n",
    "# ─── 4) EVAL HARNESS ──────────────────────────────────────────────────────\n",
    "def normalize(ans: str):\n",
    "    return re.sub(r\"[^\\d]\", \"\", ans.strip())\n",
    "\n",
    "def extract_answer(txt: str):\n",
    "    m = re.search(r\"\\\\boxed\\{(\\d+)\\}\", txt)\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "def run_aime_benchmark(n=10):\n",
    "    ds_all = load_dataset(\"rb/aime_reasoning\",\"default\")[\"train\"]\n",
    "    reserved = set(range(MAX_CV_EX)) | set(range(MAX_CLF_EX))\n",
    "    eval_idx = [i for i in range(len(ds_all)) if i not in reserved]\n",
    "    if n>len(eval_idx): n=len(eval_idx)\n",
    "    subs = random.sample(eval_idx, n)\n",
    "    records=[]\n",
    "    for i in tqdm(subs, desc=\"AIME eval\"):\n",
    "        q  = ds_all[i][\"question\"]\n",
    "        ref= normalize(str(ds_all[i][\"reference_answer\"]))\n",
    "        prompt = f\"{q}\\n\\nAnswer step by step and end with: Final answer: \\\\boxed{{numeric_value}}\"\n",
    "        # baseline\n",
    "        bt, btoks = generate_baseline(prompt, max_tokens=MAX_TOKENS)\n",
    "        # raspid\n",
    "        rt, rtoks = generate_raspid (prompt, max_tokens=MAX_TOKENS)\n",
    "        ba = normalize(extract_answer(bt))\n",
    "        ra = normalize(extract_answer(rt))\n",
    "        records.append({\n",
    "            \"question\":q,\n",
    "            \"reference\":ref,\n",
    "            \"baseline_ans\":bt, \"raspid_ans\":rt,\n",
    "            \"baseline_ok\":ba==ref, \"raspid_ok\":ra==ref,\n",
    "            \"baseline_toks\":btoks, \"raspid_toks\":rtoks\n",
    "        })\n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"\\nBaseline acc={df.baseline_ok.mean()*100:.1f}%  \"\n",
    "          f\"RASPID acc={df.raspid_ok.mean()*100:.1f}%  \"\n",
    "          f\"Avg saving={(1-df.raspid_toks/df.baseline_toks).mean()*100:.1f}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ff39bd-4e82-4342-89d0-687dcf290a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AIME eval:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** RASPID LOG START ***\n",
      "chunk | p_fluff |  err  |   α   | temp\n",
      "   64 |   0.782 | +0.732 | 0.184 | 0.871\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   0.999 | +0.949 | 0.239 | 0.833\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AIME eval: 100%|██████████| 1/1 [02:17<00:00, 137.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   64 |   1.000 | +0.950 | 0.239 | 0.832\n",
      "*** RASPID LOG END ***\n",
      "\n",
      "\n",
      "Baseline acc=100.0%  RASPID acc=100.0%  Avg saving=-109.6%\n",
      "                                            question reference  \\\n",
      "0  The sum of the squares of the roots of the equ...             \n",
      "\n",
      "                                        baseline_ans  \\\n",
      "0  The sum of the squares of the roots of the equ...   \n",
      "\n",
      "                                          raspid_ans  baseline_ok  raspid_ok  \\\n",
      "0  The sum of the squares of the roots of the equ...         True       True   \n",
      "\n",
      "   baseline_toks  raspid_toks  \n",
      "0           1954         4096  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = run_aime_benchmark(n=1)\n",
    "df.to_csv(\"aime_comparison.csv\", index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482a54b-a73a-47a0-a199-2afb251f9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"rb/aime_reasoning\",\"default\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3e1e33-a11e-4dcc-84fd-bb8137c53600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the squares of the roots of the equation $x^2+2hx=3$ is $10$. The absolute value of $h$ is equal to\n",
      "$\\textbf{(A) }-1\\qquad \\textbf{(B) }\\textstyle\\frac{1}{2}\\qquad \\textbf{(C) }\\textstyle\\frac{3}{2}\\qquad \\textbf{(D) }2\\qquad \\textbf{(E) }\\text{None of these}$\n",
      "\n",
      "Answer step by step and end with: Final answer: \\boxed{numeric_value} & & x \\\\, & & x \\\\, &, &, x \\\\, \\end{array}}}$\n",
      "\n",
      "I can summarize this in terms of a system of equations, such that:\n",
      "\n",
      "$\\frac{l}{x} + \\frac{d}{x} + \\frac{n}{x} = 1$\n",
      "\n",
      "$l + d + n = N$\n",
      "\n",
      "Wait, is that the correct way of putting it?\n",
      "\n",
      "Alternatively, perhaps integrating the position x over the time period, as per cyclic motion.\n",
      "\n",
      "But perhaps I can also consider Fourier transforms for the simultaneous analysis.\n",
      "\n",
      "Let me try that.\n",
      "\n",
      "First, define the sequence:\n",
      "\n",
      "$a_0 = l$, $a_1 = d$, $a_2 = n$, $a_3 = x$\n",
      "\n",
      "Then, in the frequency domain, the DFT is:\n",
      "\n",
      "$X(k) = l + d + n + x$, for $k=0$\n",
      "\n",
      "$X(k) = x \\cdot (\\omega^{-k} + \\omega^{-2k} + \\omega^{-3k} + 1)$, for $k=1,2,3$\n",
      "\n",
      "Where $\\omega = e^{-2\\pi i/4}$ is the fourth root of unity.\n",
      "\n",
      "Therefore, to compute these, I can compute each $X(k)$.\n",
      "\n",
      "But perhaps instead, I can use circular convolutions.\n",
      "\n",
      "Wait, perhaps the DFT of $a = [l, d, n, x]$ is:\n",
      "\n",
      "$[4l, 2l + 2d, 2l + 2d + 2n, 4(l + d + n) + x]$\n",
      "\n",
      "Wait, is that correct? Let me compute the DFT manually.\n",
      "\n",
      "For a sequence $a_0, a_1, a_2, a_3$,\n",
      "\n",
      "$X_k = \\sum_{n=0}^{3} a_n \\omega^{-kn}$, $\\omega = e^{-2\\pi i/4} = e^{-\\pi i/2} = i^{-1}$\n",
      "\n",
      "Thus, for $k=0$,\n",
      "\n",
      "$X_0 = a_0 + a_1 + a_2 + a_3 = l + d + n + x$\n",
      "\n",
      "For $k=1$,\n",
      "\n",
      "$X_1 = a_0 \\omega^{0} + a_1 \\omega^{-1} + a_2 \\omega^{-2} + a_3 \\omega^{-3}$\n",
      "\n",
      "$\\omega^{-1} = -i$, $\\omega^{-2} = -1$, $\\omega^{-3} = i$\n",
      "\n",
      "So,\n",
      "\n",
      "$X_1 = l + d(-i) + n(-1) + x(i) = l - di - n + xi$\n",
      "\n",
      "Similarly, for $k=2$,\n",
      "\n",
      "$t_k = a_0 \\omega^{0} + a_1 \\omega^{-2} + a_2 \\omega^{-4} + a_3 \\omega^{-6}$\n",
      "\n",
      "But $\\omega^4 = 1$, so $\\omega^{-4} = 1^{-1} =1$, similarly $\\omega^6 = \\omega^{4+2} = \\omega^2$\n",
      "\n",
      "$\\omega^{-2} = -1$, so\n",
      "\n",
      "$X_2 = l + d(-1) + n(1) + x(-i) = l - d + n - xi$\n",
      "\n",
      "For $k=3$,\n",
      "\n",
      "$\\omega^{-3} = i$, so\n",
      "\n",
      "$X_3 = l + d(i) + n(-1) + x(-i) = l + di - n - xi$\n",
      "\n",
      "Thus, the DFT is:\n",
      "\n",
      "$[l + d + n + x, \\ l - di - n + xi, \\ l - d +n - xi, \\ l + di -n - xi]$\n",
      "\n",
      "Wait, this seems messy, perhaps not particularly helpful.\n",
      "\n",
      "Perhaps let me define the DFT as:\n",
      "\n",
      "$Y_0 = a_0 + a_1 + a_2 + a_3$, $Y_1$, $Y_2$, $Y_3$ as above.\n",
      "\n",
      "Alternatively, perhaps computing the inverse DFT.\n",
      "\n",
      "Instead of DFT, perhaps let me think about circular convolutions.\n",
      "\n",
      "Wait, perhaps my approach is conflicting. Let me try another way.\n",
      "\n",
      "Let me see: The DFT of the sequence [l, d, n, x].\n",
      "\n",
      "We can perhaps use the fact that the circular convolution of two sequences is equal to the inverse DFT of the product of their DFTs.\n",
      "\n",
      "But perhaps this is getting complicated.\n",
      "\n",
      "Wait, going back to the problem.\n",
      "\n",
      "We need to simultaneously analyze the system, which results in a numerical matrix of size 4×4.\n",
      "\n",
      "Perhaps what is happening is that we can reconstruct the matrix through maximizing the covariance over the system.\n",
      "\n",
      "Wait, perhaps the numerical matrix is due to the projection of the position vector onto the system's incidence matrix.\n",
      "\n",
      "So, let me make this more precise.\n",
      "\n",
      "Assume that each point is located in a coordinate system where each position is represented as (x1, x2, x3), but the system's incidence matrix for the 12 systems is in 4D.\n",
      "\n",
      "Wait, but 4D is about the dimension, but perhaps since all four-dimensional points are placed into the 4D space, but what is their relation through the position x? Hmm.\n",
      "\n",
      "Wait, perhaps I can model this through a linear dimension where\n",
      "\n",
      "x is moving in a way, and l, d, n, x describe thefed vectors.\n",
      "\n",
      "Wait, perhaps thinking in terms of simultaneous linear equations.\n",
      "\n",
      "Wait, given that that the positions are related through x1 + x2 + x3 + x4 = 1, and l + d + n + x = 1, and l = d = n = x.\n",
      "\n",
      "So actually, in this case.\n",
      "\n",
      "If l = d = n = x, that's a meaningful reduction.\n",
      "\n",
      "Therefore, if l = d =n=x, then from the first equation: l + x + x + x =1, becoming l + 3x -1=0.\n",
      "\n",
      "From the second equation: l + d +n +x= same, so l +d +n= each x, so l + x +x +x =1, same.\n",
      "\n",
      "So in this case, l=d=n=x, so all four variables are equal.\n",
      "\n",
      "Assuming that.\n",
      "\n",
      "So, let l = d =n=x, then 4x =1, so x=1/4, l=1/4, d=1/4, n=1/4.\n",
      "\n",
      "Hmm, so in that case, the system is a 12x12 system, perhaps constructed with that.\n",
      "\n",
      "Alternatively, perhaps the matrices l, d, n,x are 4x4 matrices since each is a time measurement or location.\n",
      "\n",
      "Therefore, perhaps the system is 4x4, each column is a measurement.\n",
      "\n",
      "Alternatively, no, perhaps it is four equations, each measured across different points.\n",
      "\n",
      "Alternatively, perhaps each measurement is a single point of data.\n",
      "\n",
      "Wait, let's consider that.\n",
      "\n",
      "If we have 12 points, each with an x-coordinate, but these points are in a 4-dimensional space? Wait, no, if we have 12 points, each would have 4 coordinates, unless we project them into a space where x is a single coordinate.\n",
      "\n",
      "Wait, but if each point is a 4-dimensional vector, and then we have 12 such vectors, and we are facing 4 measurements.\n",
      "\n",
      "Wait, perhaps the system is built such that each measurement corresponds to one of the four coordinates, but only four measurements.\n",
      "\n",
      "Wait, the user is complaining that the system, which is 12×12, is being presented as 4×4.\n",
      "\n",
      "Alternatively, in the 4-dimensional system with 12x12, perhaps the first 4 measurements, the next 4, etc.\n",
      "\n",
      "Wait, perhaps the system is presented as 4x4 with each 4x4 block being a time measurement.\n",
      "\n",
      "Alternatively, perhaps the coordinates of each point are in the 4×4 system.\n",
      "\n",
      "Alternatively, perhaps the position x is being measured, and the four times l, d, n, x are being measured.\n",
      "\n",
      "So, perhaps it is 4 equations with 12 variables, but the user is presenting this as a 4x4 matrix.\n",
      "\n",
      "Alternatively, perhaps the problem is that given the vector v = (x, l, d, n), and the system is built so that when we have 4 measurements, we can form a matrix M, and then the system is rank-deficient, but in our case, if 4 measurements, it's full rank.\n",
      "\n",
      "Wait, actually, in such systems, we can have a matrix where each equation is a measurement.\n",
      "\n",
      "But I think the problem is to recover the position x.\n",
      "\n",
      "Wait, perhaps we have a system where x is being measured through four measurements, but each measurement provides a linear equation.\n",
      "\n",
      "Perhaps the first equation is x = l, the next is x = d, then x =n, and last x =x.\n",
      "\n",
      "Wait, but then only x = l, x =d, x =n, but if all four are equal, then x = l.\n",
      "\n",
      "Alternatively, if the system is l + d +n +x =1, and x is the location.\n",
      "\n",
      "Wait, but in that case, if l, d, n, x are known, x can be solved.\n",
      "\n",
      "Alternatively, but in the image, the first is l, second is d, third is n, fourth is x.\n",
      "\n",
      "Wait, perhaps the system is an overdetermined system, which is rank-deficient, so to get a unique solution, we need to perform some kind of optimization.\n",
      "\n",
      "Wait, to get x, perhaps, as in solving for x given some constraints.\n",
      "\n",
      "Wait, but in the problem statement, it says, \"the system is 12×12\" and \"it's unsolvable,\" but in aim, we are presented with a 4×4 matrix.\n",
      "\n",
      "Wait, perhaps I need to think as the 4x4 matrix is built from 12x12 data.\n",
      "\n",
      "Alternatively, perhaps it's to model the DFT as the matrix.\n",
      "\n",
      "Wait, getting too lost.\n",
      "\n",
      "Alternatively, perhaps I just need to set l, d, n, x so that they sum up to 1, from the DFT equations.\n",
      "\n",
      "Wait, but in the frequency domain, X(k) = l + d + n + x.\n",
      "\n",
      "But when you compute the Inverse DFT, for k=0: l + d +n +x =4*(...?), but in any case, perhaps l +d +n +x should be 4 times the DC component.\n",
      "\n",
      "Wait, maybe the DC component is l, d, n, x.\n",
      "\n",
      "Wait, yes, the DC component in DFT is sum of all elements.\n",
      "\n",
      "So, DC component is X(0) = l +d +n +x.\n",
      "\n",
      "Similarly, for other frequencies, X(1), X(2), X(3) are the DFT of the a sequence shifted by 1, 2, 3.\n",
      "\n",
      "Thus, in order to not use these shifted components, we have to reconstruct the original vector through inverse DFT.\n",
      "\n",
      "But perhaps in this case, we have to get the x from the DC component.\n",
      "\n",
      "But in order to compute the x from all these, we have to solve certain equations.\n",
      "\n",
      "So, but how to get the x.\n",
      "\n",
      "Moreover, for complex DFT or something?\n",
      "\n",
      "Wait, perhaps the system assumes all variables are real, so X(k) are real numbers.\n",
      "\n",
      "In that case, the DFT is real, so X(k) = conjugate(X(k)), so for k≠0, X(k) must be real.\n",
      "\n",
      "Which is true because l, d, n, x are real numbers, so their DFT is real only if certain symmetries.\n",
      "\n",
      "But since we are taking a linear combination.\n",
      "\n",
      "Wait, but perhaps it's going the other way.\n",
      "\n",
      "In any case, given X(k) = l +d +n +x, and for non-zero k=1,2,3:\n",
      "\n",
      "But X(1) = l -x i -n +x i\n",
      "\n",
      "Wait, but perhaps in original DFT:\n",
      "\n",
      "Wait, perhaps X(0) = l + d + n + x,\n",
      "\n",
      "X(1) = l - d - n + x,\n",
      "\n",
      "X(2) = -l + d - n - x,\n",
      "\n",
      "X(3) = l + d - n - x.\n",
      "\n",
      "No, wait, maybe.\n",
      "\n",
      "Hold on, my confusion earlier.\n",
      "\n",
      "Let me compute X(0), X(1), X(2), X(3).\n",
      "\n",
      "From the original formula,\n",
      "\n",
      "For a0 = l, a1 = d, a2 = n, a3 = x,\n",
      "\n",
      "Then,\n",
      "\n",
      "X(0) = a0 + a1 + a2 + a3 = l + d + n + x,\n",
      "\n",
      "X(1) = a0 + a1 ω^{-1} + a2 ω^{-2} + a3 ω^{-3},\n",
      "\n",
      "Compute ω^{-1} = e^{-π i /2} = -i,\n",
      "\n",
      "ω^{-2} = e^{-π i } = -1,\n",
      "\n",
      "ω^{-3} = e^{-3π i /2} = i,\n",
      "\n",
      "Thus,\n",
      "\n",
      "X(1) = l + d*(-i) + n*(-1) +x*(i) = l - di -n + xi,\n",
      "\n",
      "Similarly,\n",
      "\n",
      "X(2) = a0 + a1 ω^{-2} +a2 ω^{-4} +a3 ω^{-6}.\n",
      "\n",
      "But ω^{-4} is ω^{0} =1,\n",
      "\n",
      "ω^{-6} is ω^{ -6 mod4}= ω^{-6+8}=ω^{2}=e^{2π i(-)}= Wait, no: 6 mod4=2.\n",
      "\n",
      "Thus,\n",
      "\n",
      "X(2) =l + d*(-1)+n*(1)+x*(-i)=l -d +n -xi,\n",
      "\n",
      "Similarly,\n",
      "\n",
      "X(3) =a0 + a1 ω^{-3} + a2 ω^{-6} + a3 ω^{-9},\n",
      "\n",
      "Which is,\n",
      "\n",
      "= l +d*(i) +n*(-1) + x*(-i) = l + di -n -xi,\n",
      "\n",
      "So, that defines all four frequency components.\n",
      "\n",
      "Thus, in order to retrieve the x, l, d, n we need to invert this system.\n",
      "\n",
      "But then, if we take the system as [X(0), X(1) + X(3), X(2) - X(3)],\n",
      "\n",
      "But perhaps it's not useful.\n",
      "\n",
      "Alternatively, to get l= ?\n",
      "\n",
      "Wait, the equations are:\n",
      "\n",
      "X(0) = l + d + n + x,\n",
      "\n",
      "X(1) = l -d -n +x,\n",
      "\n",
      "X(2) = -l +d -n -x,\n",
      "\n",
      "X(3) = l +d -n -x.\n",
      "\n",
      "So, if we consider subtracting and adding these equations to isolate each variable.\n",
      "\n",
      "For example, if we add X(0) and X(1):\n",
      "\n",
      "X(0) + X(1) = 2l - n + 2x.\n",
      "\n",
      "But that includes an n which is not of interest.\n",
      "\n",
      "Similarly, if we add all four equations:\n",
      "\n",
      "X(0) + X(1) + X(2) + X(3) = 4l - 2n.\n",
      "\n",
      "Hmm, that's getting complicated.\n",
      "\n",
      "Alternatively, I can define a system.\n",
      "\n",
      "Let me label.\n",
      "\n",
      "Equation1: l + d + n + x = X(0),\n",
      "\n",
      "Equation2: l -d -n + x = X(1),\n",
      "\n",
      "Equation3: -l +d -n -x = X(2),\n",
      "\n",
      "Equation4: l +d -n -x = X(3).\n",
      "\n",
      "So, four equations.\n",
      "\n",
      "Let me try solving these.\n",
      "\n",
      "Let me denote variables as l, d, n, x.\n",
      "\n",
      "I can write them:\n",
      "\n",
      "Equation1: l + d + n + x = X0,\n",
      "\n",
      "Equation2: l - d - n + x = X1,\n",
      "\n",
      "Equation3: -l + d - n -x = X2,\n",
      "\n",
      "Equation4: l + d - n -x = X3.\n",
      "\n",
      "Let me write Equation1 - Equation2:\n",
      "\n",
      "(l + d + n +x) - (l - d -n +x) = X0 - X1\n",
      "\n",
      "Which is: 2d + 2n = X0 - X1,\n",
      "\n",
      "So, d + n = (X0 - X1)/2, let's call that A.\n",
      "\n",
      "Similarly, Equation2 - Equation1:\n",
      "\n",
      "(l - d -n +x) - (l + d +n +x) = X1 - X0\n",
      "\n",
      "-2d - 2n = X1 - X0,\n",
      "\n",
      "Which is, d + n = (X0 - X1)/2 as before.\n",
      "\n",
      "So, that is consistent.\n",
      "\n",
      "Similarly, now, equation1 + equation3.\n",
      "\n",
      "(l + d + n +x) + (-l +d -n -x) = X0 + X2,\n",
      "\n",
      "Which is: 2d = X0 + X2,\n",
      "\n",
      "Therefore, d = (X0 + X2)/2, let's call that B.\n",
      "\n",
      "Similarly, equation1 + equation4:\n",
      "\n",
      "(l + d + n +x) + (l + d -n -x) = X0 + X3,\n",
      "\n",
      "Which is: 2l + 2d = X0 + X3,\n",
      "\n",
      "Thus, l + d = (X0 +X3)/2,\n",
      "\n",
      "But since d is (X0 +X2)/2, so plugging in,\n",
      "\n",
      "( (X0 +X2)/2 + (X0 +X3)/2 ) = (X0 + X2 + X0 +X3)/2 = (2X0 +X2 + X3)/2,\n",
      "\n",
      "Thus, l = (2X0 +X2 +X3)/2 - (X0 +X2)/2,\n",
      "\n",
      "Which is (2X0 +X2 +X3 -X0 -X2)/2 = (X0 + X3)/2,\n",
      "\n",
      "So, l = (X0 + X3)/2, let's call that C.\n",
      "\n",
      "Similarly, d = (X0 + X2)/2, as above,\n",
      "\n",
      "From equation1: l + d +n +x =X0,\n",
      "\n",
      "So, n is X0 - l -d -x,\n",
      "\n",
      "But we have l and d, so n = X0 - (X0 + X3)/2 - (X0 + X2)/2 -x,\n",
      "\n",
      "Compute:\n",
      "\n",
      "= X0 - ( (X0 + X3) + (X0 + X2) ) /2 - x,\n",
      "\n",
      "= (2X0 - (2X0 + X2 + X3))/2 -x,\n",
      "\n",
      "= ( -X2 - X3 ) /2 -x,\n",
      "\n",
      "= - (X2 + X3)/2 -x,\n",
      "\n",
      "Hmm, a bit complicated. Maybe not necessary.\n",
      "\n",
      "Alternatively, since we have d = (X0 + X2)/2, n = ?\n",
      "\n",
      "n is from equation3 or equation2.\n",
      "\n",
      "From equation3: -l +d -n -x = X2,\n",
      "\n",
      "Plugging in l = (X0 + X3)/2, d = (X0 + X2)/2,\n",
      "\n",
      "We get: - (X0 + X3)/2 + (X0 + X2)/2 -n -x = X2,\n",
      "\n",
      "Which simplifies,\n",
      "\n",
      "Left side:\n",
      "\n",
      "- (X0 + X3)/2 + (X0 + X2)/2 -n -x,\n",
      "\n",
      "= (-X0 - X3 +X0 +X2 ) /2 -n -x,\n",
      "\n",
      "= (X2 - X3)/2 -n -x = X\n"
     ]
    }
   ],
   "source": [
    "print(df['raspid_ans'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932fa77b-eb2c-4c9b-8a23-c5a487bdcae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's try to solve this problem step by step. The question is asking for the value of a nested absolute value expression when x is -2016. The expression is:\\n\\nBigg\\\\vert\\\\Big\\\\vert |x|-x\\\\Big\\\\vert-|x|\\\\Bigg\\\\vert - x\\n\\nAnd the options are given as (A) -2016, (B) 0, (C) 2016, (D) 4032, (E) 6048.\\n\\nFirst, let me parse the expression correctly. It's important to handle the absolute value signs properly, especially since they are nested. Let's break it down from the inside out.\\n\\nGiven that x = -2016, which is a negative number. Let's note that |x| is the absolute value of x, so |x| would be 2016 in this case.\\n\\nStarting with the innermost part: |x|. Since x is -2016, |x| = |-2016| = 2016.\\n\\nThen, the next part is |x| - x. Let's substitute the values here. We already know |x| is 2016, and x is -2016. So:\\n\\n|x| - x = 2016 - (-2016) = 2016 + 2016 = 4032.\\n\\nWait, that seems like a big number. Let me check that again. Absolute value of x is positive, so 2016. Then subtracting x, which is -2016, so subtracting a negative is adding the positive. So yes, 2016 - (-2016) = 4032. That's correct.\\n\\nNext, we take the absolute value of that result. So we have | |x| - x | = |4032|. But 4032 is already positive, so the absolute value doesn't change it. So this part is still 4032.\\n\\nNow, the next layer is subtracting |x| from this result. So:\\n\\n| |x| - x | - |x| = 4032 - 2016 = 2016.\\n\\nAgain, let me verify that. The first absolute value gave us 4032, then we subtract |x| which is 2016, so 4032 - 2016 is indeed 2016.\\n\\nThen, we take the absolute value of that result. So:\\n\\n| (| |x| - x | - |x| ) | = |2016| = 2016.\\n\\nSince 2016 is positive, the absolute value doesn't affect it. So now, we have this result, which is 2016, and the entire expression then subtracts x. So the entire expression is:\\n\\n| (| |x| - x | - |x| ) | - x = 2016 - (-2016) = 2016 + 2016 = 4032.\\n\\nWait, but 4032 is option D. However, let me double-check each step because these absolute value problems can be tricky.\\n\\nLet me outline each step again with x = -2016:\\n\\n1. Compute |x|: |-2016| = 2016.\\n\\n2. Compute |x| - x: 2016 - (-2016) = 4032.\\n\\n3. Take absolute value of that: |4032| = 4032.\\n\\n4. Subtract |x| from that: 4032 - 2016 = 2016.\\n\\n5. Take absolute value of the result: |2016| = 2016.\\n\\n6. Subtract x: 2016 - (-2016) = 4032.\\n\\nYes, that seems correct. So the answer should be 4032, which is option D.\\n\\nBut let me check once more to be thorough. Maybe I missed a sign somewhere.\\n\\nOriginal expression:\\n\\n|| |x| - x | - |x| | - x\\n\\nBreaking it down:\\n\\nStart with the inner absolute value: |x| = 2016.\\n\\nThen |x| - x: 2016 - (-2016) = 4032.\\n\\nTake absolute value: |4032| = 4032.\\n\\nThen subtract |x|: 4032 - 2016 = 2016.\\n\\nTake absolute value of that: |2016| = 2016.\\n\\nSubtract x: 2016 - (-2016) = 4032.\\n\\nYes, that seems consistent. So the answer is D) 4032.\\n\\nAlternatively, maybe there's another approach. Let me think.\\n\\nSince x is negative, let's let x = -a, where a is positive (a = 2016). Then let's rewrite the expression in terms of a.\\n\\nGiven x = -a,\\n\\nCompute || |x| - x | - |x| | - x\\n\\nFirst, |x| = |-a| = a.\\n\\nThen |x| - x = a - (-a) = a + a = 2a.\\n\\nAbsolute value: |2a| = 2a.\\n\\nSubtract |x|: 2a - a = a.\\n\\nAbsolute value: |a| = a.\\n\\nSubtract x: a - (-a) = a + a = 2a.\\n\\nSince a = 2016, 2a = 4032.\\n\\nYes, same result. So using substitution with a positive variable also leads to the same answer. This method might be less error-prone because dealing with positive variables can make the operations clearer.\\n\\nTherefore, confirming again, the answer is D) 4032.\\n\\n**Final Answer**\\n\\\\boxed{D}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['reasoning_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c4d8c5-0584-4206-8bcf-8790c206479d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Given \\\\( x = -2016 \\\\), evaluate the expression \\\\( || |x| - x | - |x| | - x \\\\).\\n2. Compute \\\\( |x| \\\\): \\\\( | -2016 | = 2016 \\\\).\\n3. Evaluate \\\\( |x| - x \\\\): \\\\( 2016 - (-2016) = 2016 + 2016 = 4032 \\\\).\\n4. Take the absolute value: \\\\( |4032| = 4032 \\\\).\\n5. Subtract \\\\( |x| \\\\): \\\\( 4032 - 2016 = 2016 \\\\).\\n6. Take the absolute value of the result: \\\\( |2016| = 2016 \\\\).\\n7. Subtract \\\\( x \\\\): \\\\( 2016 - (-2016) = 2016 + 2016 = 4032 \\\\).\\n8. Conclusively, the value of the expression is \\\\( 4032 \\\\), which corresponds to option (D).\\n\\nFinal answer: \\\\(\\\\boxed{D}\\\\)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['refined_reasoning']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
